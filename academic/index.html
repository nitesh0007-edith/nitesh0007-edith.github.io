<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Nitesh Ranjan Singh | MSc Data Science</title>
  <link href="https://fonts.googleapis.com/css2?family=Inter:wght@300;500;700&display=swap" rel="stylesheet" />
  <style>
    :root {
      --bg-color: #f9f9f9;
      --text-color: #333;
      --primary-color: #0d3b66;
      --nav-color: #133b5c;
      --card-bg: #fff;
      --card-border: #eee;
    }
    [data-theme="dark"] {
      --bg-color: #121212;
      --text-color: #f1f1f1;
      --primary-color: #1e90ff;
      --nav-color: #1c1c1c;
      --card-bg: #1e1e1e;
      --card-border: #333;
    }
    * {
      box-sizing: border-box;
    }
    body {
      margin: 0;
      font-family: 'Inter', sans-serif;
      background-color: var(--bg-color);
      color: var(--text-color);
      transition: background 0.3s, color 0.3s;
      line-height: 1.6;
    }
    header {
      background: url('cover.jpeg') no-repeat center center;
      background-size: cover;
      color: #fff;
      padding: 5rem 1rem 4rem;
      text-align: center;
      position: relative;
    }
    header::before {
      content: "";
      position: absolute;
      inset: 0;
      background: rgba(13, 59, 102, 0.75);
    }
    header * {
      position: relative;
    }
    header img {
      width: 110px;
      height: 110px;
      border-radius: 50%;
      margin-bottom: 1rem;
      object-fit: cover;
      border: 3px solid white;
    }
    header h1 {
      margin: 0;
      font-size: 2.2rem;
    }
    header p {
      margin: 0.5rem 0 0;
      font-size: 1.05rem;
    }
    nav {
      background-color: var(--nav-color);
      display: flex;
      flex-wrap: wrap;
      justify-content: center;
      gap: 1rem;
      padding: 1rem;
    }
    nav a, .theme-toggle {
      color: #fff;
      text-decoration: none;
      font-weight: 500;
      cursor: pointer;
      font-size: 0.95rem;
      padding: 0.4rem 0.6rem;
    }
    nav a:hover {
      text-decoration: underline;
    }
    .theme-toggle {
      background: none;
      border: 1px solid #fff;
      border-radius: 4px;
    }
    .content {
      max-width: 1140px;
      margin: 2.5rem auto;
      padding: 0 2rem;
    }
    .section {
      margin-bottom: 3rem;
      display: none;
      text-align: justify;
    }
    .section.active {
      display: block;
      animation: fadeIn 0.6s ease-in-out;
    }
    @keyframes fadeIn {
      from { opacity: 0; transform: translateY(20px); }
      to { opacity: 1; transform: translateY(0); }
    }
    .section h2 {
      color: var(--primary-color);
      border-bottom: 2px solid var(--primary-color);
      padding-bottom: 0.3rem;
      font-size: 1.7rem;
      margin-bottom: 1.5rem; /* Increased margin */
    }
    .contact-form input, .contact-form textarea {
      width: 100%;
      padding: 0.6rem;
      margin-bottom: 1rem;
      border: 1px solid #ccc;
      border-radius: 4px;
      font-family: 'Inter', sans-serif;
    }
    .contact-form button {
      background-color: var(--primary-color);
      color: #fff;
      border: none;
      padding: 0.6rem 1rem;
      border-radius: 4px;
      cursor: pointer;
    }
    footer {
      background-color: var(--primary-color);
      color: #fff;
      text-align: center;
      padding: 1rem;
      margin-top: 4rem;
      font-size: 0.9rem;
    }
    ul {
      padding-left: 1.4rem;
      margin-bottom: 1rem;
    }
    li {
      margin-bottom: 0.5rem;
    }

    /* === NEW STYLES FOR PROJECTS SECTION === */
    .project-card {
      background: var(--card-bg);
      border: 1px solid var(--card-border);
      border-radius: 8px;
      padding: 1.5rem;
      margin-bottom: 2rem;
      box-shadow: 0 4px 8px rgba(0,0,0,0.05);
      transition: transform 0.2s, box-shadow 0.2s;
    }
    .project-card:hover {
        transform: translateY(-5px);
        box-shadow: 0 6px 12px rgba(0,0,0,0.1);
    }
    .project-title {
        font-size: 1.4rem;
        font-weight: 700;
        margin-bottom: 0.5rem;
    }
    .project-title a {
        color: var(--primary-color);
        text-decoration: none;
    }
    .project-title a:hover {
        text-decoration: underline;
    }
    .project-description {
        margin-bottom: 1rem;
    }
    .project-tech {
        display: flex;
        flex-wrap: wrap;
        gap: 0.5rem;
        margin-top: 1rem;
    }
    .tech-tag {
        background-color: var(--primary-color);
        color: #fff;
        padding: 0.2rem 0.6rem;
        border-radius: 4px;
        font-size: 0.8rem;
        font-weight: 500;
    }
    /* === END OF NEW STYLES === */

    @media (max-width: 600px) {
      header h1 {
        font-size: 1.6rem;
      }
      header p {
        font-size: 0.95rem;
      }
      nav {
        gap: 0.8rem;
        padding: 0.8rem;
      }
      nav a {
        font-size: 0.85rem;
      }
      .content {
        padding: 0 1rem;
      }
    }
    @media (min-width: 1200px) {
      body {
        font-size: 1.05rem;
        line-height: 1.7;
      }
    }
  </style>
</head>
<body>
  <header>
    <img src="image1.png" alt="Nitesh Ranjan Singh">
    <h1>Nitesh Ranjan Singh</h1>
    <p>MSc Data Science @ University of Glasgow | Data Engineer | Azure | PySpark</p>
  </header>

  <nav>
    <a onclick="showSection('welcome')">Welcome</a>
    <a onclick="showSection('about')">About</a>
    <a onclick="showSection('experience')">Work Experience</a>
    <a onclick="showSection('education')">Education</a>
    <a onclick="showSection('projects')">Projects</a>
    <a onclick="showSection('contact')">Contact</a>
    <a href="Nitesh-Singh-Resume.pdf">Resume</a>
    <a href="https://github.com/nitesh0007-edith" target="_blank">GitHub</a>
    <a href="https://www.linkedin.com/in/nitesh0007/" target="_blank">LinkedIn</a>
    <button class="theme-toggle" onclick="toggleTheme()">ðŸŒ“</button>
  </nav>

  <div class="content">
    <section class="section active" id="welcome">
      <h2>Welcome!</h2>
      <p>Hello and welcome to my professional portfolio. I am <strong>Nitesh Ranjan Singh</strong>, a passionate and forward-thinking <strong>Data Engineer</strong> with over <strong>three years of experience</strong> in designing and optimizing scalable data pipelines using modern cloud technologies like <strong>Azure Data Factory</strong>, <strong>Databricks</strong>, <strong>PySpark</strong>, and <strong>Snowflake</strong>. Iâ€™ve made impactful contributions in the pharmaceutical and healthcare analytics sectors at <strong>IQVIA</strong> and <strong>Axtria</strong>, and have been recognized with <strong>IQVIAâ€™s Impact Award</strong> for my achievements.</p>
      <p>Currently, I am pursuing an <strong>MSc in Data Science</strong> at the <strong>University of Glasgow</strong>, where Iâ€™m expanding my knowledge in advanced machine learning, big data analytics, and cloud-native data engineering practices. Iâ€™m honored to be a recipient of the <strong>Â£10,000 Excellence Scholarship</strong> and excited to engage with industry-aligned research and projects.</p>
      <p>This portfolio is a curated collection of my professional journey, academic growth, technical projects, and career aspirations in data engineering and AI-driven infrastructure. Thank you for visiting, and I invite you to explore the sections ahead to learn more about my work and interests.</p>
    </section>

    <section class="section" id="about">
      <h2>About Me</h2>
      <p>Hello! I'm <strong>Nitesh Ranjan Singh</strong>, a passionate and driven data professional currently pursuing an <strong>MSc in Data Science</strong> at the <strong>University of Glasgow</strong>. With over <strong>three years of experience as a Data Engineer</strong> in the pharmaceutical and healthcare analytics industry, Iâ€™ve designed and optimized large-scale ETL pipelines using technologies like <strong>Azure Data Factory</strong>, <strong>Databricks</strong>, <strong>PySpark</strong>, and <strong>Snowflake</strong>.</p>
      <p><strong>Why Data Science?</strong><br>My fascination with data began during my undergraduate studies in Computer Science, where I explored machine learning and built AI-based systems like <em>DigiAttendance</em> â€” a facial recognition attendance tracker. Over time, working at organizations like <strong>IQVIA</strong> and <strong>Axtria</strong>, I witnessed how impactful data can be in driving real-world decisions â€” especially in healthcare. This blend of technology, business context, and data-driven insight led me to pursue data science more deeply. I enjoy building systems that not only process data efficiently but also unlock hidden patterns and empower decision-makers.</p>
      <p><strong>Why the UK and the University of Glasgow?</strong><br>I chose the UK for its strong alignment with industry-focused academic programs, access to a vibrant tech ecosystem, and excellent post-study work opportunities. The University of Glasgowâ€™s <strong>Data Science MSc program</strong> stood out to me for its well-balanced curriculum in big data analytics, cloud computing, and applied machine learning, backed by global faculty and research standards. Receiving a <strong>Â£10,000 Excellence Scholarship</strong> was both a recognition and a motivation to invest my full potential into this transformative journey.</p>
      <p><strong>Career Goals</strong><br>My short-term goal is to secure a <strong>data engineering internship in the UK</strong> during the summer of 2026, where I can apply my skills in Azure, Spark, and data pipeline design in a real-world setting. Long-term, I aspire to become a <strong>Data Engineering Lead or Solutions Architect</strong>, working at the intersection of cloud infrastructure, machine learning, and AI Ops â€” building scalable data products that serve both technical and business outcomes.</p>
    </section>

    <section class="section" id="experience">
      <h2>Work Experience</h2>
      <ul>
        <li><strong>Data Engineer â€“ IQVIA, Gurgaon, India</strong><br><strong>Dec 2022 â€“ Aug 2025</strong><br>
          <div style="margin: 0.5rem 0;">
            <span style="display:inline-block;background:#007FFF;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Azure</span>
            <span style="display:inline-block;background:#2D7DD2;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">ADF</span>
            <span style="display:inline-block;background:#FF6F00;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Databricks</span>
            <span style="display:inline-block;background:#0078D4;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">ADLS</span>
            <span style="display:inline-block;background:#1E90FF;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Azure SQL</span>
            <span style="display:inline-block;background:#008080;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Synapse</span>
            <span style="display:inline-block;background:#3572A5;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Python</span>
            <span style="display:inline-block;background:#E27D60;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">PySpark</span>
            <span style="display:inline-block;background:#FFB347;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">SQL</span>
            <span style="display:inline-block;background:#F2C94C;color:black;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Power-BI</span>
            <span style="display:inline-block;background:#6C757D;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Excel</span>
          </div>
          As a Data Engineer, I design and implement robust data workflows that enhance the delivery of analytical insights for clients across Europe. By integrating Python, SQL, PySpark, and Azure Databricks, I automate complex data processes, develop efficient data pipelines, and optimize reporting frameworks. These pipelines support high-quality Power BI and Excel dashboards, enabling timely and accurate reporting on a weekly, monthly, and quarterly basis.<br><br>
          <strong>Key highlights:</strong>
            <ul>
              <li>Automated the data refresh process by shifting from a time-based trigger to an event-based trigger using Azure Data Factory (ADF), Azure SQL, and Power BI, eliminating manual intervention in extract refresh workflows by 100%.</li>
              <li>Orchestrated and scaled a robust data ingestion and validation pipeline to process business-user-delivered files with over 100 million records using PySpark on Azure Databricks, ensuring alignment with standard data formats without modifying raw files, achieving zero data loss.</li>
              <li>Implemented advanced data quality rules within the ETL pipelines using SQL and PySpark, enabling early detection of data anomalies and significantly improving data consistency and conformity across downstream systems.</li>
              <li>Designed and developed an automated anomaly detection dashboard using Python and Power BI, minimizing manual data validation efforts by 95% and proactively preventing critical data quality issues.</li>
              <li>Enabled and fixed high-impact data quality checks as part of the pipeline design in Azure Synapse and Azure SQL, which led to a 90% reduction in recurring data issues.</li>
              <li>Optimized and re-engineered data pipelines to support three daily refreshes using ADF, Azure Databricks, and ADLS, improving data freshness and conformity by 95%, and ensuring readiness for analytics and reporting layers.</li>
            </ul>
        </li><br><br>
        <li><strong>Analyst â€“ Axtria, Noida, India</strong><br><strong>Jan 2022 â€“ Dec 2022</strong><br>
          <div style="margin: 0.5rem 0;">
            <span style="display:inline-block;background:#3572A5;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Python</span>
            <span style="display:inline-block;background:#E27D60;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">PySpark</span>
            <span style="display:inline-block;background:#FFB347;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">SQL</span>
            <span style="display:inline-block;background:#F2C94C;color:black;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Power BI</span>
            <span style="display:inline-block;background:#6C757D;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Excel</span>
            <span style="display:inline-block;background:#232F3E;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Databricks</span>
            <span style="display:inline-block;background:#D42029;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Redshift</span>
            <span style="display:inline-block;background:#00A3E0;color:white;border-radius:4px;padding:0.2rem 0.6rem;margin:0.2rem;font-size:0.8rem;">Athena</span>
          </div>
          As an entry-level Analyst, I supported the development of data and reporting solutions by collaborating with cross-functional teams in the pharmaceutical analytics space. My responsibilities included data extraction, transformation, and visualization using SQL, Python, and BI tools. This role was foundational in building my understanding of end-to-end data workflows and stakeholder-driven reporting.<br><br>
          <strong>Key highlights:</strong>
          <ul>
            <li>Developed and maintained automation scripts using Python to extract data from API-based sources, standardize file formats, and automate file transfers via SFTP to Amazon S3 and within S3, supporting scalable and efficient data ingestion workflows.</li>
            <li>Owned and ensured delivery of high-quality data pipelines for data transformation and loading using SQL and Matillion on the AWS ecosystem, enabling timely and accurate reporting for stakeholders.</li>
            <li>Worked extensively with pharmaceutical datasets including Veeva, Specialty Pharmacy, IQVIA LAAD, and other healthcare data sources to analyze trends, derive insights, and address complex business requirements raised by clients.</li>
            <li>Designed and delivered dynamic, client-facing dashboards using Power BI, transforming raw data into actionable insights and supporting data-driven decision-making across business functions.</li>
          </ul>
        </li>
      </ul>
    </section>

    <section class="section" id="education">
      <h2>Education</h2>
      <ul>
        <li>
          <strong>MSc Data Science â€“ University of Glasgow, UK</strong><br>
          <em>Expected: 2026</em>
          <ul>
            <li>Modules: Big Data Analytics, Cloud Computing, Data Engineering</li>
            <li>Scholarship: Â£10,000 Excellence Award</li>
            <li>Project: Built scalable ETL pipeline using ADF, Databricks & ADLS Gen2 for healthcare data</li>
          </ul>
        </li>
        <br>
        <li>
          <strong>B.Tech in Computer Science Engineering â€“ University of Petroleum and Energy Studies, India</strong><br>
          <em>2018 â€“ 2022</em>
          <ul>
            <li>Final Year Project: DigiAttendance â€“ AI-based attendance system using facial recognition</li>
          </ul>
        </li>
      </ul>
    </section>

    <section class="section" id="projects">
      <h2>Latest Projects</h2>
      
      <div class="project-card">
        <h3 class="project-title"><a href="https://github.com/nitesh0007-edith" target="_blank">AutoPipelineAI</a></h3>
        <p class="project-description">
          This project addresses a key bottleneck in data operations: the time and expertise required to build custom ETL pipelines. AutoPipelineAI is a proof-of-concept Data-Ops framework that empowers users to generate and deploy data workflows using natural language, effectively democratizing data engineering tasks.
        </p>
        <ul>
            <li><b>Core Functionality:</b> Users input data transformation requirements (e.g., "load the customer CSV, filter for UK clients, and aggregate sales by city") into a Streamlit-based web interface.</li>
            <li><b>LLM Integration:</b> The framework leverages a locally-hosted Llama3 model via Ollama to interpret the prompt and generate production-quality, executable PySpark code for the required transformations.</li>
            <li><b>Automated Orchestration:</b> The generated script is then automatically packaged into a container and integrated into a dynamic Azure Data Factory pipeline, ready for immediate execution or scheduling. This showcases a practical application of AI in automating cloud infrastructure and MLOps.</li>
        </ul>
        <div class="project-tech">
            <span class="tech-tag">Python</span>
            <span class="tech-tag">Generative AI</span>
            <span class="tech-tag">Streamlit</span>
            <span class="tech-tag">Ollama</span>
            <span class="tech-tag">Llama3</span>
            <span class="tech-tag">Data-Ops</span>
            <span class="tech-tag">Azure</span>
        </div>
      </div>

      <div class="project-card">
        <h3 class="project-title"><a href="https://github.com/nitesh0007-edith" target="_blank">Digi-Attendance</a></h3>
        <p class="project-description">
          A complete, end-to-end facial recognition system designed to automate workplace attendance, eliminating the need for manual check-ins or physical ID cards. The system was built with efficiency and accuracy as primary goals, capable of running on low-cost edge devices.
        </p>
        <ul>
            <li><b>Real-Time Video Processing:</b> The application uses OpenCV to capture a live video stream, identifying and isolating faces in each frame in real-time.</li>
            <li><b>Face Encoding & Recognition:</b> For each detected face, the `face_recognition` library generates a unique 128-d numerical encoding. This encoding is then compared against a pre-computed database of known employee faces to find a match with high accuracy.</li>
            <li><b>User Interface & Data Logging:</b> A user-friendly GUI built with PyQt5 allows for easy management of the system. All successful recognitions are logged to a CSV file with a precise timestamp, which is then used to automatically calculate total working hours.</li>
        </ul>
        <div class="project-tech">
            <span class="tech-tag">Python</span>
            <span class="tech-tag">OpenCV</span>
            <span class="tech-tag">face_recognition</span>
            <span class="tech-tag">PyQt5</span>
            <span class="tech-tag">Computer Vision</span>
        </div>
      </div>

      <div class="project-card">
        <h3 class="project-title"><a href="https://github.com/nitesh0007-edith" target="_blank">Mathematical Model for Linear Data</a></h3>
        <p class="project-description">
          This project demonstrates a foundational mastery of machine learning principles by building a complete linear regression model from scratch to analyze the factors influencing crime rates in the US. By avoiding high-level libraries like Scikit-learn, this work showcases a deep understanding of the underlying mathematics.
        </p>
        <ul>
            <li><b>Manual Implementation:</b> Implemented the entire gradient descent algorithm using only NumPy to train the model, including manual calculation of the cost function (MSE), derivatives, and iterative weight updates.</li>
            <li><b>Data Analysis & Feature Engineering:</b> Performed exploratory data analysis on the US Crime Data dataset to identify and select relevant predictive features, preparing the data for the model without relying on automated tools.</li>
            <li><b>Exceptional Performance:</b> The final model achieved a Mean Squared Error (MSE) of <b>0.0452</b> and an R-squared (RÂ²) value of <b>0.9835</b>, indicating an extremely high level of accuracy and predictive power, validating the correctness of the from-scratch implementation.</li>
        </ul>
        <div class="project-tech">
            <span class="tech-tag">Python</span>
            <span class="tech-tag">NumPy</span>
            <span class="tech-tag">Linear Regression</span>
            <span class="tech-tag">Data Analysis</span>
            <span class="tech-tag">Statistics</span>
        </div>
      </div>

    </section>

    <section class="section" id="contact">
      <h2>Contact Me</h2>
      <form class="contact-form" action="https://formspree.io/f/mqalezed" method="POST">
        <input type="text" name="name" placeholder="Your Name" required />
        <input type="email" name="email" placeholder="Your Email" required />
        <textarea name="message" rows="5" placeholder="Your Message" required></textarea>
        <button type="submit">Send Message</button>
      </form>
    </section>
  </div>

  <footer>
    &copy; 2025 Nitesh Ranjan Singh | Glasgow, UK
  </footer>

  <script>
    function showSection(id) {
      document.querySelectorAll('.section').forEach(section => {
        section.classList.remove('active');
      });
      document.getElementById(id).classList.add('active');
    }

    function toggleTheme() {
      const theme = document.documentElement.getAttribute("data-theme");
      document.documentElement.setAttribute("data-theme", theme === "dark" ? "light" : "dark");
    }

    // Default to welcome section on page load
    document.addEventListener('DOMContentLoaded', () => {
        showSection('welcome');
    });
  </script>
</body>
</html>
